{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e907d20e",
   "metadata": {},
   "source": [
    "# Sample a dataset from a (multilingual) corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a3fcbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "import re\n",
    "\n",
    "# To create your own samples, download the corpora from the OPUS website: https://opus.nlpl.eu/\n",
    "sample_size = 1000\n",
    "dataset_path_base = \"path-to-opus-datasets/Europarl-v7/en-es\"\n",
    "dataset_filename_pattern = \"Europarl-v7.en-es.<LANG>\"\n",
    "sample_filename_pattern = \"Europarl-v7.en-es.sample.01.<LANG>.txt\"\n",
    "index_filename = \"Europarl-v7.en-es.sample_indices.01.txt\"\n",
    "languages = [\"en\", \"es\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7eb450a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate random indices\n",
    "def generate_random_indices(valid_lines, sample_size):\n",
    "    return sorted(random.sample(valid_lines, sample_size))\n",
    "\n",
    "# Function to save indices\n",
    "def save_indices(indices, file_path):\n",
    "    with open(file_path, 'w') as file:\n",
    "        file.write('\\n'.join(map(str, indices)))\n",
    "\n",
    "# Function to load indices\n",
    "def load_indices(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        return [int(line.strip()) for line in file]\n",
    "\n",
    "# Function to check if a line contains alphabet characters\n",
    "def is_valid_line(line):\n",
    "    return bool(re.search(\"[a-zA-Z]\", line))\n",
    "\n",
    "# Check and collect valid lines that are valid across all languages\n",
    "def get_valid_lines_across_languages(languages, dataset_path_base, dataset_filename_pattern):\n",
    "    file_paths = [os.path.join(dataset_path_base, dataset_filename_pattern.replace(\"<LANG>\", lang)) for lang in languages]\n",
    "    files = [open(path, 'r', encoding=\"utf-8\") for path in file_paths]\n",
    "    valid_indices = []\n",
    "    index = 0  # Initialize line index\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            lines = [next(f).strip() for f in files]\n",
    "            if all(is_valid_line(line) for line in lines):\n",
    "                valid_indices.append(index)\n",
    "            index += 1  # Increment line index after checking each line\n",
    "    except StopIteration:\n",
    "        pass  # Ends when any file runs out of lines\n",
    "    finally:\n",
    "        for f in files:\n",
    "            f.close()\n",
    "    return valid_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4bf4dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if index file exists and if it does not, create it\n",
    "index_file = os.path.join(dataset_path_base, index_filename)\n",
    "if not os.path.exists(index_file):\n",
    "    valid_lines = get_valid_lines_across_languages(languages, dataset_path_base, dataset_filename_pattern)\n",
    "\n",
    "    # Ensure there are enough valid lines to sample\n",
    "    if len(valid_lines) < sample_size:\n",
    "        raise ValueError(f\"Not enough valid lines to sample. Only found {len(valid_lines)} valid lines.\")\n",
    "\n",
    "    # Generate random line numbers from valid lines\n",
    "    random_line_numbers = generate_random_indices(valid_lines, sample_size)\n",
    "    \n",
    "    # Save the indices\n",
    "    save_indices(random_line_numbers, index_file)\n",
    "else:\n",
    "    # Load indices from file\n",
    "    random_line_numbers = load_indices(index_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb5db93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process each language using the shared indices\n",
    "for language_code in languages:\n",
    "    input_file = os.path.join(dataset_path_base, dataset_filename_pattern.replace(\"<LANG>\", language_code))\n",
    "    output_file = os.path.join(dataset_path_base, sample_filename_pattern.replace(\"<LANG>\", language_code))\n",
    "\n",
    "    # Extract the sampled lines\n",
    "    with open(input_file, 'r', encoding=\"utf-8\") as file:\n",
    "        lines = file.readlines()\n",
    "        with open(output_file, 'w', encoding=\"utf-8\") as output:\n",
    "            for i in random_line_numbers:\n",
    "                output.write(lines[i])\n",
    "\n",
    "    print(f\"Sample of {sample_size} lines has been written to {output_file}\")\n",
    "\n",
    "print(\"Sample generation finished for all languages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43226756-9cc1-431b-b5d1-b7612046b858",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
