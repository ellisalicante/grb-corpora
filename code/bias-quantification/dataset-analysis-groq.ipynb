{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83971a35",
   "metadata": {},
   "source": [
    "# Gender representation bias quantification\n",
    "\n",
    "Analysis of gender representation bias in a given dataset using Groq API inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a3fcbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openpyxl\n",
    "from groq import Groq\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "\n",
    "model = \"llama-3.3-70b-versatile\"\n",
    "#model = \"qwen-2.5-32b\"\n",
    "lang = \"es\"\n",
    "#lang = \"va\"\n",
    "prompt_pathname = f\"../../data/dataset-analysis/prompt-{lang}.txt\" # prompt pattern\n",
    "examples_pathname = f\"../../data/dataset-analysis/examples-{lang}.txt\" # few-shot examples\n",
    "skiplist_pathname = f\"../../data/dataset-analysis/skiplist-{lang}.txt\" # skip list (words to be ignored)\n",
    "dataset_pathname = f\"../../data/corpora-en-es/Europarl-v7.en-es.sample.01.{lang}.txt\" # dataset to be analyzed\n",
    "results_pathname = dataset_pathname.replace(\"/data/\", \"/results/\").replace(\".txt\", f\"_{model}_grbresults.xlsx\") # results file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b74c51-cdb5-4738-92e0-35bfd87fbac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference using Groq API\n",
    "def inference(client, prompt):\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320289d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out any lines from the response text whose first token (before ' - ') is in the skip list\n",
    "def filter_skiplist(response_text, skip_words):\n",
    "    lines = response_text.splitlines()\n",
    "    filtered_lines = []\n",
    "    for line in lines:\n",
    "        if \" - \" in line: # check if the line contains the expected delimiter\n",
    "            word = line.split(\" - \")[0].strip().upper()\n",
    "            if word in skip_words:\n",
    "                continue  # skip this line if the word is in the skip list\n",
    "        filtered_lines.append(line)\n",
    "    return \"\\n\".join(filtered_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a7365a-95fc-433b-9b9a-4ed0e9ddb255",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_excel_with_analysis(client, prompt_pattern, examples, sentences, results_pathname, skiplist=None):\n",
    "    # Create a new workbook and select the active worksheet\n",
    "    workbook = openpyxl.Workbook()\n",
    "    worksheet = workbook.active\n",
    "    \n",
    "    # Add headers to the worksheet\n",
    "    worksheet.append([\"ID\", \"Sentence\", \"Analysis\"])\n",
    "    \n",
    "    # Iterate through the sentences and perform analysis\n",
    "    for i, sentence in tqdm_notebook(enumerate(sentences, start=1), total=len(sentences)):\n",
    "        prompt = prompt_pattern.replace(\"<EXAMPLES>\", examples).replace(\"<SENTENCE>\", sentence[:-1]) # [:-1] to remove trailing newline character\n",
    "        response = inference(client, prompt)\n",
    "\n",
    "        # Filter out skiplist words from the response\n",
    "        filtered_response = filter_skiplist(response, skiplist) if skiplist is not None else response\n",
    "        \n",
    "        # Append the sentence and its analysis to the worksheet\n",
    "        worksheet.append([i, sentence[:-1], filtered_response])\n",
    "        \n",
    "        # Save the workbook after every line\n",
    "        workbook.save(results_pathname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfcf7cc-effe-4da7-ba7f-54df3c48e271",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize statistics\n",
    "def initialize_counters():\n",
    "    return {\n",
    "        'total_words': 0,\n",
    "        'count_M': 0,\n",
    "        'count_F': 0,\n",
    "        'count_N': 0,\n",
    "        'count_P': 0,\n",
    "        'count_P_M': 0,\n",
    "        'count_P_F': 0\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aad118d-c893-4c72-9c63-6e38a9a14fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update statistics with a single sentence analysis\n",
    "def update_counters(counters, sentence_analysis):\n",
    "    words = sentence_analysis.split('\\n')\n",
    "    counters['total_words'] += len(words)\n",
    "    \n",
    "    for word in words:\n",
    "        if ', M' in word:\n",
    "            counters['count_M'] += 1\n",
    "        if ', F' in word:\n",
    "            counters['count_F'] += 1\n",
    "        if 'N, ' in word:\n",
    "            counters['count_N'] += 1\n",
    "        if 'P, ' in word:\n",
    "            counters['count_P'] += 1\n",
    "        if 'P, M' in word:\n",
    "            counters['count_P_M'] += 1\n",
    "        if 'P, F' in word:\n",
    "            counters['count_P_F'] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d89f401-8cc7-4c97-b517-c0d96c7ed5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the saved Excel file\n",
    "def analyze_excel_file(pathname):\n",
    "    workbook = openpyxl.load_workbook(pathname)\n",
    "    worksheet = workbook.active\n",
    "    \n",
    "    counters = initialize_counters()\n",
    "\n",
    "    for row in worksheet.iter_rows(min_row=2, values_only=True):\n",
    "        sentence_analysis = row[2]\n",
    "        update_counters(counters, sentence_analysis)\n",
    "\n",
    "    return counters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c639e24d-e15a-4131-b458-aaa73750808e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(counters, pathname=None):\n",
    "    # Prepare statistics output\n",
    "    summary = (f\"Total number of identified words: {counters['total_words']}\\n\"\n",
    "               f\"Number of words that are *, M: {counters['count_M']}\\n\"\n",
    "               f\"Number of words that are *, F: {counters['count_F']}\\n\"\n",
    "               f\"Number of words that are N, *: {counters['count_N']}\\n\"\n",
    "               f\"Number of words that are P, *: {counters['count_P']}\\n\"\n",
    "               f\"Number of words that are P, M: {counters['count_P_M']}\\n\"\n",
    "               f\"Number of words that are P, F: {counters['count_P_F']}\\n\"\n",
    "               f\"Ratio (P, M) : (P, F): {counters['count_P_M']/counters['count_P_F'] if counters['count_P_F'] != 0 else float('inf'):.2f} : 1\")\n",
    "\n",
    "    print(summary)  # Print to terminal\n",
    "    if pathname is not None:\n",
    "        with open(pathname, 'w') as f:\n",
    "            print(summary, file=f)  # Print to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7eb450a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read files\n",
    "with open(examples_pathname, 'r', encoding=\"utf-8\") as examples_file:\n",
    "    examples = examples_file.read()\n",
    "\n",
    "with open(dataset_pathname, 'r', encoding=\"utf-8\") as dataset_file:\n",
    "    sentences = dataset_file.readlines()\n",
    "\n",
    "with open(prompt_pathname, 'r', encoding=\"utf-8\") as prompt_file:\n",
    "    prompt_pattern = prompt_file.read()\n",
    "\n",
    "with open(skiplist_pathname, 'r', encoding='utf-8') as skiplist_file:\n",
    "    if skiplist_pathname is not None:\n",
    "        skiplist = {line.strip().upper() for line in skiplist_file if line.strip()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afbe1c5c-9a2a-4cb0-9b99-06ce2eb31877",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run inference\n",
    "client = Groq(api_key=os.environ.get(\"GROQ_API_KEY\"))\n",
    "os.makedirs(os.path.dirname(results_pathname), exist_ok=True)\n",
    "create_excel_with_analysis(client, prompt_pattern, examples, sentences, results_pathname, skiplist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c33b150-b9e4-412e-b0fe-b01af17dba5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis summary (statistics)\n",
    "stats = analyze_excel_file(results_pathname)\n",
    "print_results(stats, results_pathname.replace(\".xlsx\", \".txt\"))\n",
    "os.path.basename(results_pathname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472211a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
